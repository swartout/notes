---
layout: default
title: CSE 351
parent: CSE
---

# CSE 351

---

## Lecture 1 - June 21

- We will cover three main topics:
    - Data
    - Programs
    - Scale
- The prefix for binary is: `0b`, hex prefix is: `0x`
- With $n$ binary digits we can represent $2^n$ things
    - With $n$ digits of base $b$ we can represent $b^n$ things
- ASCII characters are one byte, representing 256 characters
    - lol we have so much more memory now, hello UTF encoding

---

## Lecture 2 - June 23

- The CPU executes instructions which are also stored in memory
- CSE 351 is about data movement - how is memory stored or found?
- Base-2 is the default (although DNA/quantum computing is researched)
- We manipulate memory as chunks of bytes (even if it doesn't need all bits - hello bools!)
- Definition "word": a 8-byte chunk of memory
- x86-64 systems use 64-bit words
    - The potential address space is 2^64 addresses
- Pointers are also stored in memory like any other data
- Big-endian: least signifcant byte stored in the *largest* address
    - Not commonly used
- Little-endian: least significant byte stored in *smallest* address
    - x86, x86-64
- Bi-endian (used on ARM/M1)
- The pointer always points to the lowest address of the data

---

## Lecture 3 - June 26

- Pointers are defined: `type* ptr;`
    - The `type` encodes size information, the `*` designates it is a pointer
- To get the address of a variable, write: `type* ptr = &var;`
    - The address must be stored in a pointer
- The "dereference" operator `*` is used to "grab" the data a pointer points to
    - i.e. `int num = *ptr;`
- `NULL` is a special pointer to nothing
- Addition of a pointer and a scalar scales the scalar by the size of the type
- Subtraction of two pointers the value is scaled (divided) by the size of the type
    - We can use this to find the amount of `type`s between two pointers
- Arrays are sets of contiguous locations in memory that store the same type of data object
    - C declaration: `type name[size]`
    - Indexing actually works with: `*(array_name + n)`
- "Strings" in C are actually just arrays of chars terminated by the null character
    - i.e. `char str[] = "hi"` allocates an array of size three
    - Null character is backslash 0
        - not every array in C has this null character
- In C, declaration does *not* mean initialization: there can be garbage data

---

## Lecture 4 - June 28

- `0` is false, everything else is true
- Bitwise operators:
    - AND: `&`
    - OR:  `|`
    - XOR: `^`
    - NOT: `~`
- Logical operators:
    - AND: `&&`
    - OR:  `||`
    - NOT: `!`
- Unsigned integers work as expected
- Signed integers use: *Two's Complement*
    - The weight of the most significant bit is negative
    - This means `-x == ~x + 1`
- Bitmasking allows us to change our inputs as we want

---

## Lecture 5 - June 30

- Signed/unsigned integers are represented in memory the same way
- Type casting includes:
    - Changes in bit-widths
    - Changes in interpretation
    - Full changes in representations
- Implicit casting happens when there is a type mismatch, but a well defined conversion between the two types
- Explicit casts: `(new_type) expression`
- When casting between bit-widths, we must extend the data
    - Zero extension: padding with extra zeros on the left (preserves the value)
    - Sign extension: pad signed data with copies on most signficant bit (preserves sign and value)
- Operations between signed and unsigned values implicitly cast all values to unsigned representations
- Fixed-with binary arithmatic is modular
    - This results in integer overflow
- Bit shifting: move all bits a specified amount in a direction, filling in what is lost
    - Left shift: `x << n` fills in `n` zeros on the right
    - Logical right shift: `x >> n` where `x` is unsigned, fills in zeros on the left
    - Arithmetic right shift: `x >> n` where `x` is signed, fills in with copies of most significant bit on the left
- Bit shifting can be interpreted as integer multiplication or division by powers of two
- To force unsigned ints, we must append number with `u` or `U`

---

## Lecture 6 - July 5

- Masking in C: `#define SEARCH replace`
- IEEE 754 floating point encoding uses *normalized scientific binary notation*:
    - This includes the sign, mantissa, and exponent
    - 32 and 64 bit encodings for float and long
- Sign is represented using just a single bit
- Exponent is biased notation:
    - The value is shifted by: $2^{w - 1} - 1$ where $w$ is the width of the exponent field
    - Bias is a zero followed by all ones: `0b01...1`
    - Bias is an unsigned int
    - Positive is one bigger
- Mantissa:
    - Implicit leading one: $1.M$, not actually stored
    - Can lead to [weird rounding errors](https://0.30000000000000004.com)
- 32 bit encoding (float):
    - first bit is sign
    - next 8 bits are exponent
    - last 23 bits are mantissa
- 64 bit encoding (long):
    - first bit is sign
    - next 11 bits are exponent
    - last 52 bits are mantissa
- Steps to go from FP -> decimal:
    1. Append the bits of $M$ to implicit leading 1 to form the mantissa.
    2. Multiply the mantissa by $2^{\text{E - bias}}$
    3. Multiply the sign $(-1)^{\text{S}}$
    4. Multiply out the exponent by shifting the binary point.
    5. Convert from binary to decimal.
- Steps to go from decimal -> FP:
    1. Convert decimal to binary.
    2. Convert binary to normalized scientific notation.
    3. Encode the sign as $S$ (0 or 1).
    4. Encode $E$ as exponent + bias in unsigned.
    5. Encode the 23 bits after the binary point (padding with trailing 0's as needed) into $M$
- Precision is the number of bits in a computer word to represent a value
    - Gives capacity for accuracy
- Accuracy is a measure of the difference between the true and computer representations of a value
- If the exponent and mantissa are zeros, the float is zero
- If the exponent is all ones and mantissa is zero, it is positive or negative zero
- If the exponent is all ones and mantissa is *not* zero, it is not a number (`NaN`)
    - The mantissa will store some value about what went wrong
- When the exponent is zero and the mantissa is *not* zero, we have denormalized numbers
    - This fills in the gaps between 0 and a real number
- FP errors:
    - Overflow: exp too large
    - Underflow: exp too small
    - Rounding: between possible numbers

---

## Lecture 7 - July 7

- Instruction set architecture (ISA) is the processor spec necessary to write assembly code
    - System state: all information that defines culmination of past instructions
    - Instruction set: list and format of all instructions the CPU can execute
    - The effect on the system state of each instruction
- The spectrum of ISAs falls between CISC and RISC:
    - CISC: complex instruction set computer, easy for programmers but harder for hardware
    - RISC: reduced instruction set computer, easier for hardware but low-level programming
- x86-64 is CISC, we will only look at integral data and use "AT&T" syntax
- In x86-64 assembly, instructions are specified using a short instruction name followed by 0-3 operands
    - We will primarily look at instructions with 1-2 operands
    - "AT&T" syntax typically follows:
        - `instr op`
        - `instr src, dest`
- Main types of x86-64 instructions:
    - Data transfer: copy data from one place to another
    - Arithmetic and logical operations
    - Control flow
- Each instruction includes a "size specifier" letter appended:
    - `b` for byte
    - `w` word (two bytes)
    - `l` long word (4 bytes)
    - `q` quad word (8 bytes)
- `addb` does integer addition using a byte data width
- Operands for x86-64 are one of three types:
    1. Immediates: constant integer data, uses `$` prefix
    2. Registers: name of any of the 16 general purpose registers, uses `%` prefix
    3. Memory: specific address, ususally dereferenced, parenthesis before a `%`
- For binary instructions (two operands), the operations can be used in any combination *except:*
    - Immediate cannot be used as a destination operand
    - No memory to memory operation (both operations cannot be Memory)
- A register is a location in the CPU which stores small amount of data (word size) which can be accessed quickly
    - Fixed number per architecture
        - x86-64 has 16 with 8-byte word size
    - Referred by name, different for smaller divisions
    - Some registers are reserved
- Register names referring to smaller divisions always refer to *least significant bytes* of the register
    - `%ax` refers to the lowest two bytes of `%rax`
- When a smaller register name is used, the upper bytes are untouched **except:**
    - Any instruction that generates a 32-bit value for a register also sets the higher bits to all zeros (x86-64)
- General way to express Memory operand: `D(Rb,Ri,S)`
    - `D`: displacement value, must be an immediate or constant
    - `Rb`: base register, name of the register which acts as the "base" of our address calculation
    - `Ri`: index register, name of the register whos value will be scaled and added to the base
    - `S`: scale factor, scales the value in `Ri` by the specified number, must be 1, 2, 4, or 8
- The computed address is: `Reg[Rb] + Reg[Ri] \* S + D` where `Reg[]` means "the value in the register specified"
    - Most instructions will dereference this, giving the *memory* of this
- Default values of Memory operand:
    - `D = 0`
    - `Reg[Rb] = 0`
    - `Reg[Ri] = 0`
    - `S = 1`
- GCC and Clang can compile down to x86-64 or ARM instruction sets
- Assembly doesn't have "data types", only byte amounts
- "Moving" data actually is more similar to copying data

---

## Lecture 8 - July 10

- Calling conventions: for assembly functions
    - We store first argument in `%rdi`
    - We store second argument in `%rsi`
    - Return value is stored in `%rax`
- Addressing modes:
    - We can use parenthesis to dereference pointers i.e. `(%rax)`
- Remember registers can store pointers as well!
- `leaq src, dst`: load effective address
    - Breaks the rules :/
    - `src` is address expression
    - `dst` is a register
    - Sets `dst` to the address computed by the `src` expression
        - Only does math, doesn't do memory stuff
- As multiplication is an expensive operation, it is often broken down to bitshifts and additions
- `%rip` stores a pointer to the next instruction we will execute
- There are one bit "condition codes" which store one-bit of memory and are implicitly set
    - `CF` carry flag
    - `ZF` zero flag
    - `SF` sign flag
    - `OF` overflow flag
- Compare `cmpq a, b` sets condition codes by doing `b - a`
- `testq a, b` does the same, setting codes with `a&b`
    - `testq a, a` allows us to test based on an existing value
- `jmp` is unconditional
    - Updates `%rip`
- `set*` sets the lowest byte of a register to 0 or 1 based on current condition codes

---

## Lecture 9 - July 12

- Extension instructions: `movz` and `movs`
    - Similar to the `mov` command, but source operand is shorter than the dest operand
    - Performs `z`ero extension and `s`ign extension
    - Requires two width specifier suffixes
- Conditionals are typically made up of two instructions:
    1. Logical instruction that sets/changes the condition codes (`cmp`, `test`)
    2. A conditional jump instruction (`j*`)
- Operand to a jump instruction is a label
    - Name followed by a colon, i.e. `main:`
    - Labels are symbolic, representing the location of the next instruction found
- Loops are made by using a jump statement to go backwards to beginning of loop body
    - Conditionals can be at the top or bottom of the loop
- Switch statement branches condition depending on a value
    - Need to `break` to prevent falling through cases
    - Jump table has an "array" of pointers to code
    - Those code blocks are contiguous
- `ja`: jump to the default case (unsigned case)
- `jmp *.L4(,%rdi,8)`: jump table, index starting at `.L4`

---

## Lecture 10/11 - July 17

- The stack is a section of memory which takes up the highest possible address space
    - Holds local variables and procedural context
    - It grows downwards, occupying lower addresses as it needs more space
    - The end of the stack is indicated by the address stored in the stack pointer `%rsp`
- Stack pointer can be modified by `subq` and `addq`, allocation and deallocation
    - Doesn't affect any data stored in memory
- Stack pointer can also be modified with `push src` and `pop dest`
    - `push` decrements `%rsp` then copies data from source to `%rsp`
    - `pop` copies data from `%rsp` to `dest`, then increments `%rsp`
- Calling conventions: ensure proecdures can pass data and control one another
    - We store a return value on the stack, pointer to what the caller should execute next
    - To pass control to another procedure we use the `call label` instruction
    - To return control we use the `ret` instruction
- To pass arguments we must use specific registers
    - "Diane's Silk Dress Cost $89" is a memonic
    - All other arguments must be placed on the stack in reverse order
- The return value must be placed in `%rax`
    - This could be a pointer to the return value
- Stack frames are a way of enabling recursion, dividing our stack into chunks
    - Each of these frames are for only one call
- Stack frame layout:
    1. return address from `call`
    2. (optional) `%rbp` frame pointer, indicator of the beginning of the current frame
    3. Old register values need to be pushed, followed by local variables
    4. If this calls another procedure, more register values and arguments 7+
- As any procedure can overwrite registers, we have register saving conventions
    - Calle-saved registers it is the callee's responsibility to save the old value before using the register
        - Restores the old value before returning
    - Caller-saved registers it is the responsibility of the caller to save the old value before passing control

---

## Lecture 12 - July 19

- A buffer is a region of memory used to temporarly store data
- A buffer *overflow* is writing past the end of the buffer into adjacent memory
- Stack smashing is writing past the end of a local array in the stack
    - We can write back enough in the frame to overwrite the return address
- `gets()` can write user input past the end of an array
- Code injection:
    1. Write exploit code/binary and put it at the start of the buffer
    2. Pad to the end of the stack frame
    3. Replace return address with buffer address (exploit code)
- Good practice when exploiting someone's code not to mess with past stack frames, so normal operation can be resumed

---

## Lecture 13 - July 21

- Process of building and running an executable has four phases - CALL:
    - Compiling
    - Assembling
    - Linking 
    - Loading
- Building an executable is the first three phases
    - This is done by `gcc`
- Compiling:
    - Compiler translates a text file of source code to a text file of assembly
        1. In C, preprocessor step which runs command that start with `#`
        2. Interpret the meaning of the code and convert to assembly
    - We can supply compiler optimization flags to `gcc` to change certain attributes
- Assembly:
    - Assembler converts a text file of assembly code to a binary object file
        - These contain *object code* which is incomplete machine code
        - The object code is incomplete because it lacks the addresses associated with the labels of the final executable
    - In order to patch the object code, we create two tables:
        1. Symbol table: list of globally-accessible labels
        2. Relocation table: list of the addresses to be patched
- Linking:
    - The linker stiches together the object and static library files necessary to build the final executable
    - Links all the symbol and relocation tables
    - "Unresolved symbols" (i.e. undefined function) will lead to failure
- Disassembling:
    - Reading binary code and interpreting it as instructions is disassembling
    - `ghidra` my beloved
- Loading:
    - The loader takes an executable and starts a running process
    - Sets up memory sections and initializes register values
    - Primarily handled by the OS
- Arrays in assembly:
    - The name of an array `arr` in C is turned into a placeholder for the starting address of an array
    - Array subscription (`arr[idx]`) in assembly is: `D(,Ri,S)` with `D` the array name/label, `Reg[Ri]` the index, and `S` = `sizeof(T)`
- Multidimensional arrays are a contiguous chunk of memory for all arrays
    - Accessing an element is an address calculation followed by a single memory acceess
- Multilevel arrays do not require a large contiguous block of memory, but extra memory accesses
    - Stores pointers vs arrays, allows variable array sizes

---

## Lecture 14 - July 24

- A struct in C is a user-defined, structured group of variables
    - Defining a struct: `struct struct_tag {type1 field1; ...}`
    - Declaring a struct variable instance: `struct struct_tag my_struct_var;`
        - The initial `struct` does not need to be written if you typedef it
    - Possible to also declare and intialize a struct at once, use `*ptr` to declare pointer
- Struct name can (typically) only be used *after* it was defined and in scop
- Used to allow compiler or program to understand the size and layout of the struct
- A struct can have fields of any type *except* itself (but can have pointers to itself)
- Fields are accessed with `.` operator or `->` from a pointer
- As two word data type names are unweildy, we often combine them with `typedef`:
    - i.e. `typedef unsigned int uint;`
    - This can be done with structs after defintion or while defining:
        - `typedef struct {type1 field1; ...} struct_tag;`
- A primitive object of `K` bytes in memory is *aligned* if `address % K = 0`
- The struct layout follows the ordering of the fields with padding inserted such that each field is aligned
    - The padding (unused space) is known as *internal fragmentation*
- The overall size of the struct also needs to be alligned:
    - `overall_size % K_max = 0` where `K_max` is the largest type in the fields
    - This padding is called *external fragmentation`

---

## Lecture 15 - July 26

- IEC prefixes use a base 1024 and refer to large numbers in computing
- Caches (**$**) are intermediate places of storing memory for a short time
    - Data is transferred between caches and memory in blocks, machine-specified units larger than a word
- When accessing memory, the machine checks the cache first:
    - If the data is in the cache, that is a *cache hit*
    - Otherwise it must be fetched from memory and stored in the cache, a *cache miss*
        - Placement policy determines where the block is placed
        - Replacement policy determines what memory is removed from the cache
- The principle of locality: programs tend to use data at addresses near to what was used recently
    - **Temporal locality:** referenced items are likely to be referenced in the near future
    - **Spatial locality:** items with nearby addresses tend to be referenced close together in time
- Cache performance metrics:
    - **Hit Time:** how long a cache hit takes
    - **Miss Penalty:** how long it takes to fetch a block of data from memory
    - **Hit/Miss Rate:** the fraction of memory accesses that result in a hit or miss respectively
    - Average Memory Access Time = `hit time + miss rate * miss penalty`
- There are typically multiple levels of caching
    - Some are closer (quicker) to memory
    - Block size might differ between cache levels
    - AMAT is calculated for overall system caching
